{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Policy Gradient\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the pg_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile pg_autograde.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6607b79e73a101a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a10fe31897025f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Policy Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34f0712f792bbcca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to implement policy gradient, we will first implement a class with a policy network. Although in general this does not have to be the case, we will use an architecture very similar to the Q-network that we used (two layers with ReLU activation for the hidden layer). Since we have discrete actions, our model will output one value per action, where each value represents the (normalized!) probability of selecting that action. *Use the softmax activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a31440f9477f963",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "class NNPolicy(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor (first dimension is a batch dimension)\n",
    "            \n",
    "        Return:\n",
    "            Probabilities of performing all actions in given input states x. Shape: batch_size x action_space_size\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if len(x.shape) != 2:\n",
    "            x = x.unsqueeze(0)\n",
    "            assert x.shape[1] == 4\n",
    "        out = self.l2(self.relu(self.l1(x)))\n",
    "\n",
    "        return self.softmax(out)\n",
    "        \n",
    "    def get_probs(self, obs, actions):\n",
    "        \"\"\"\n",
    "        This function takes a tensor of states and a tensor of actions and returns a tensor that contains \n",
    "        a probability of perfoming corresponding action in all states (one for every state action pair). \n",
    "\n",
    "        Args:\n",
    "            obs: a tensor of states. Shape: batch_size x obs_dim\n",
    "            actions: a tensor of actions. Shape: batch_size x 1\n",
    "\n",
    "        Returns:\n",
    "            A torch tensor filled with probabilities. Shape: batch_size x 1.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        probs = self.forward(obs)\n",
    "        action_probs = probs[torch.arange(len(actions)), actions.long().squeeze()]\n",
    "        return action_probs.unsqueeze(1)\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: state as a tensor. Shape: 1 x obs_dim or obs_dim\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            probs = self.forward(obs.T)\n",
    "\n",
    "        distr = torch.distributions.Categorical(probs)\n",
    "        action = distr.sample()\n",
    "\n",
    "        return int(action.item())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d280fe6520edc91",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[0.4578, 0.5422],\n",
      "        [0.4657, 0.5343],\n",
      "        [0.4563, 0.5437],\n",
      "        [0.4634, 0.5366],\n",
      "        [0.4564, 0.5436],\n",
      "        [0.4725, 0.5275],\n",
      "        [0.4769, 0.5231],\n",
      "        [0.4834, 0.5166],\n",
      "        [0.4797, 0.5203],\n",
      "        [0.4618, 0.5382]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4578],\n",
      "        [0.5343],\n",
      "        [0.5437],\n",
      "        [0.4634],\n",
      "        [0.4564],\n",
      "        [0.5275],\n",
      "        [0.4769],\n",
      "        [0.5166],\n",
      "        [0.4797],\n",
      "        [0.4618]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "policy = NNPolicy(num_hidden)\n",
    "\n",
    "states = torch.rand(10, 4)\n",
    "actions = torch.randint(low=0, high=2, size=(10,1))\n",
    "print(actions)\n",
    "\n",
    "# Does the outcome make sense?\n",
    "forward_probs = policy.forward(states)\n",
    "print(forward_probs)\n",
    "assert forward_probs.shape == (10,2), \"Output of forward has incorrect shape.\"\n",
    "sampled_action = policy.sample_action(states[0])\n",
    "assert sampled_action == 0 or sampled_action == 1, \"Output of sample action is not 0 or 1\"\n",
    "\n",
    "action_probs = policy.get_probs(states, actions)\n",
    "print(action_probs)\n",
    "assert action_probs.shape == (10,1), \"Output of get_probs has incorrect shape.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Monte Carlo REINFORCE\n",
    "\n",
    "Now we will implement the *Monte Carlo* policy gradient algorithm. Remember that this means that we will estimate returns for states by sample episodes. Compared to DQN, this means that we do *not* perform an update step at every environment step, but only at the end of each episode. This means that we should generate an episode of data, compute the REINFORCE loss (which requires computing the returns) and then perform a gradient step.\n",
    "\n",
    "* You can use `torch.multinomial` to sample from a categorical distribution.\n",
    "* The REINFORCE loss is defined as $- \\sum_t \\log \\pi_\\theta(a_t|s_t) G_t$, which means that you should compute the (discounted) return $G_t$ for all $t$. Make sure that you do this in **linear time**, otherwise your algorithm will be very slow! Note the - (minus) since you want to maximize return while you want to minimize the loss.\n",
    "\n",
    "To help you, we wrote down signatures of a few helper functions. Start by implementing a sampling routine that samples a single episode (similarly to the one in Monte Carlo lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "def sample_episode(env, policy):\n",
    "    \"\"\"\n",
    "    A sampling routine. Given environment and a policy samples one episode and returns states, actions, rewards\n",
    "    and dones from environment's step function as tensors.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of tensors (states, actions, rewards, dones). All tensors should have same first dimension and \n",
    "        should have dim=2. This means that vectors of length N (states, rewards, actions) should be Nx1.\n",
    "        Hint: Do not include the state after termination in states.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    states.append(torch.FloatTensor(env.reset()).unsqueeze(1))\n",
    "    actions.append(policy.sample_action(states[-1]))\n",
    "\n",
    "    while True:\n",
    "        state, reward, done, _ = env.step(int(actions[-1]))\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        if not done:\n",
    "            states.append(torch.FloatTensor(state).unsqueeze(1))\n",
    "            actions.append(policy.sample_action(states[-1]))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    assert len(states) == len(actions) == len(rewards) == len(dones)\n",
    "\n",
    "    states = torch.stack(states).squeeze()\n",
    "    actions = torch.FloatTensor(actions).unsqueeze(1)\n",
    "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "    dones = torch.Tensor(dones).unsqueeze(1)\n",
    "    \n",
    "    return states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janzuiderveld/miniconda3/envs/rl2020/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# Let's sample some episodes\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "policy = NNPolicy(num_hidden)\n",
    "for episode in range(3):\n",
    "    trajectory_data = sample_episode(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement loss computation and training loop of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f6e32c4931392bf",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "def compute_reinforce_loss(policy, episode, discount_factor):\n",
    "    \"\"\"\n",
    "    Computes reinforce loss for given episode.\n",
    "\n",
    "    Args:\n",
    "        policy: A policy which allows us to get probabilities of actions in states with its get_probs method.\n",
    "\n",
    "    Returns:\n",
    "        loss: reinforce loss\n",
    "    \"\"\"\n",
    "    # Compute the reinforce loss\n",
    "    # Make sure that your function runs in LINEAR TIME\n",
    "    # Note that the rewards/returns should be maximized \n",
    "    # while the loss should be minimized so you need a - somewhere\n",
    "    # YOUR CODE HERE\n",
    "    # print(episode)\n",
    "    states, actions, rewards, _ = episode\n",
    "\n",
    "    action_probs = policy.get_probs(states, actions)\n",
    "    log_probs = -torch.log(action_probs)\n",
    "\n",
    "    # discount_factors = discount_factor ** torch.arange(len(rewards))\n",
    "    # total_returns = rewards * discount_factors\n",
    "    \n",
    "    Gt = []\n",
    "    for t in range(len(rewards)):\n",
    "        summed_rewards = 0\n",
    "        discount_power = 0\n",
    "        for reward in rewards[t:]:\n",
    "            summed_rewards += reward * (discount_factor ** discount_power)\n",
    "            discount_power += 1\n",
    "        Gt.append(summed_rewards)\n",
    "    Gt = torch.FloatTensor(Gt).squeeze()\n",
    "\n",
    "    loss = torch.sum(log_probs.squeeze() * Gt)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def run_episodes_policy_gradient(policy, env, num_episodes, discount_factor, learn_rate, \n",
    "                                 sampling_function=sample_episode):\n",
    "    optimizer = optim.Adam(policy.parameters(), learn_rate)\n",
    "    \n",
    "    episode_durations = []\n",
    "    for i in range(num_episodes):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        episode = sampling_function(env, policy)\n",
    "        episode_durations.append(len(episode[0]))\n",
    "\n",
    "        loss = compute_reinforce_loss(policy, episode, discount_factor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                           \n",
    "        if i % 10 == 0:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                  .format(i, len(episode[0]), '\\033[92m' if len(episode[0]) >= 195 else '\\033[99m'))\n",
    "        \n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smoothing function for nicer plots\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 19 steps\n",
      "\u001b[99m Episode 10 finished after 9 steps\n",
      "\u001b[99m Episode 20 finished after 42 steps\n",
      "\u001b[99m Episode 30 finished after 15 steps\n",
      "\u001b[99m Episode 40 finished after 24 steps\n",
      "\u001b[99m Episode 50 finished after 26 steps\n",
      "\u001b[99m Episode 60 finished after 37 steps\n",
      "\u001b[99m Episode 70 finished after 27 steps\n",
      "\u001b[99m Episode 80 finished after 48 steps\n",
      "\u001b[99m Episode 90 finished after 107 steps\n",
      "\u001b[99m Episode 100 finished after 20 steps\n",
      "\u001b[99m Episode 110 finished after 75 steps\n",
      "\u001b[99m Episode 120 finished after 55 steps\n",
      "\u001b[99m Episode 130 finished after 73 steps\n",
      "\u001b[99m Episode 140 finished after 37 steps\n",
      "\u001b[99m Episode 150 finished after 43 steps\n",
      "\u001b[99m Episode 160 finished after 60 steps\n",
      "\u001b[99m Episode 170 finished after 52 steps\n",
      "\u001b[99m Episode 180 finished after 15 steps\n",
      "\u001b[92m Episode 190 finished after 367 steps\n",
      "\u001b[99m Episode 200 finished after 44 steps\n",
      "\u001b[99m Episode 210 finished after 36 steps\n",
      "\u001b[99m Episode 220 finished after 54 steps\n",
      "\u001b[92m Episode 230 finished after 227 steps\n",
      "\u001b[99m Episode 240 finished after 139 steps\n",
      "\u001b[92m Episode 250 finished after 271 steps\n",
      "\u001b[99m Episode 260 finished after 161 steps\n",
      "\u001b[99m Episode 270 finished after 143 steps\n",
      "\u001b[99m Episode 280 finished after 156 steps\n",
      "\u001b[99m Episode 290 finished after 98 steps\n",
      "\u001b[92m Episode 300 finished after 225 steps\n",
      "\u001b[92m Episode 310 finished after 438 steps\n",
      "\u001b[92m Episode 320 finished after 345 steps\n",
      "\u001b[99m Episode 330 finished after 140 steps\n",
      "\u001b[99m Episode 340 finished after 134 steps\n",
      "\u001b[99m Episode 350 finished after 148 steps\n",
      "\u001b[92m Episode 360 finished after 215 steps\n",
      "\u001b[92m Episode 370 finished after 322 steps\n",
      "\u001b[99m Episode 380 finished after 123 steps\n",
      "\u001b[92m Episode 390 finished after 500 steps\n",
      "\u001b[99m Episode 400 finished after 95 steps\n",
      "\u001b[92m Episode 410 finished after 283 steps\n",
      "\u001b[99m Episode 420 finished after 186 steps\n",
      "\u001b[92m Episode 430 finished after 221 steps\n",
      "\u001b[92m Episode 440 finished after 500 steps\n",
      "\u001b[92m Episode 450 finished after 370 steps\n",
      "\u001b[92m Episode 460 finished after 500 steps\n",
      "\u001b[92m Episode 470 finished after 205 steps\n",
      "\u001b[92m Episode 480 finished after 500 steps\n",
      "\u001b[92m Episode 490 finished after 500 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10e0f4860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feel free to play around with the parameters!\n",
    "num_episodes = 500\n",
    "discount_factor = 0.99\n",
    "learn_rate = 0.001\n",
    "seed = 42\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "policy = NNPolicy(num_hidden)\n",
    "\n",
    "episode_durations_policy_gradient = run_episodes_policy_gradient(\n",
    "    policy, env, num_episodes, discount_factor, learn_rate)\n",
    "\n",
    "plt.plot(smooth(episode_durations_policy_gradient, 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend(['Policy gradient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the pg_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('rl2020': conda)",
   "language": "python",
   "name": "python37364bitrl2020conda0cfbea289ed047d48770808c55ef4fd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
